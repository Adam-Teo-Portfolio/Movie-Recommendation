{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b41188a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import re \n",
    "\n",
    "# Load Datasets\n",
    "# --------------\n",
    "# Read in files and drop unused columns\n",
    "def readin(file, drop=[]):\n",
    "    return pd.read_csv(f\"data/{file}.csv\").drop(columns=drop)\n",
    "    \n",
    "ratings = readin(\"ratings\", drop=[\"timestamp\"])\n",
    "movies  = readin(\"movies\")\n",
    "tags    = readin(\"tags\", drop=[\"timestamp\",\"userId\"]) \n",
    "\n",
    "# print(\n",
    "#     f\"ratings : {ratings.shape}\\n\"\n",
    "#     f\"movies  : {movies.shape}\\n\"\n",
    "#     f\"tags    : {tags.shape}\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "390ed32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redduce movies.csv\n",
    "# ------------------\n",
    "# 1) Remove the movies that have only gotten a few reviews\n",
    "mask = ratings.groupby(\"movieId\")[\"rating\"].count() > 100\n",
    "mask = mask[mask]\n",
    "movies_r = movies[ movies[\"movieId\"].isin(mask.index) ].copy()\n",
    "\n",
    "# 2) Remove the movies that have a very low ratings\n",
    "mask = ratings.groupby(\"movieId\")[\"rating\"].mean() > 3.8\n",
    "mask = mask[mask]\n",
    "movies_r = movies_r[ movies_r[\"movieId\"].isin(mask.index) ] \n",
    "\n",
    "# movies_r.shape, movies.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2fcef71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce tags.csv\n",
    "# ---------------\n",
    "# 1) Remove all movies from tags.csv that was removed from movies.csv\n",
    "tags_temp = tags[ tags[\"movieId\"].isin(movies_r[\"movieId\"]) ].copy()\n",
    "\n",
    "# 2) Set all tags to lower case\n",
    "tags_temp[\"tag\"] = tags_temp[\"tag\"].astype(str)\n",
    "tags_temp[\"tag\"] = tags_temp[\"tag\"].map(lambda x: x.lower())\n",
    "\n",
    "# 3) Remove the least frequent tags \n",
    "mask = tags_temp.groupby(\"tag\")[\"tag\"].count() > 1000\n",
    "mask = mask[mask]\n",
    "tags_r = tags_temp[ tags_temp[\"tag\"].isin(mask.index) ]\n",
    "\n",
    "# tags_r.shape, tags.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d4c6172f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce ratings.csv\n",
    "# ------------------\n",
    "# 1) Reduce ratings\n",
    "ratings_r = ratings[ ratings[\"movieId\"].isin(movies_r[\"movieId\"])].copy()\n",
    "\n",
    "# ratings_r.shape, ratings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4be0d98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split movies.csv\n",
    "# ----------------\n",
    "# 1) Split movies in to titles and genres \n",
    "titles_r = movies_r.copy()\n",
    "titles_r.drop(columns=[\"genres\"], inplace=True)\n",
    "\n",
    "genres_r = movies_r.copy()\n",
    "genres_r.drop(columns=[\"title\"], inplace=True)\n",
    "\n",
    "# 2) Explode the genres column in movies_r\n",
    "def explode(df, id_column, explode_column, split_marker):\n",
    "    expand = list()\n",
    "  \n",
    "    # Transforms the DataFrame in to a list with the exploded columns\n",
    "    for index, row in df.iterrows(): \n",
    "        expand.extend( (row[id_column], gen.lower()) for gen in row[explode_column].split(split_marker)  )\n",
    "\n",
    "    # Transforms the list back in to a DataFrame\n",
    "    df_new = pd.DataFrame({id_column:[tu[0] for tu in expand], explode_column:[tu[1] for tu in expand]})\n",
    "    return df_new\n",
    "\n",
    "genres_r = explode(genres_r, \"movieId\", \"genres\", \"|\")\n",
    "\n",
    "# 3) Som movies have been taged with genres, \n",
    "#    to avoid duplicates 'tags = genres' are removed from tags  \n",
    "mask = tags_r[\"tag\"].isin(genres_r[\"genres\"].unique())\n",
    "tags_r = tags_r[~mask]\n",
    "\n",
    "# movies_r.shape, titles_r.shape, genres_r.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8848e5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cosine For Tags\n",
    "# ---------------   \n",
    "# 1) Combine genres and tags\n",
    "genres_rc = genres_r.copy()\n",
    "tags_rc = tags_r.copy()\n",
    "tags_genres_combined = pd.concat([tags_rc, genres_rc.rename(columns={\"genres\":\"tag\"})])\n",
    "tags_genres_combined.reset_index(drop=True, inplace=True)\n",
    "tags_genres_combined.drop_duplicates(inplace=True)\n",
    "\n",
    "# 2) Create Pivot Table\n",
    "tags_genres_combined[\"ones\"]=1\n",
    "tags_genres_pivot = tags_genres_combined.pivot(index=\"movieId\", columns=\"tag\", values=\"ones\")\n",
    "tags_genres_pivot.fillna(0, inplace=True)\n",
    "\n",
    "# 3) Create cosine matrix\n",
    "cosine_sim_matrix = cosine_similarity(tags_genres_pivot)\n",
    "cosine_sim_id = pd.DataFrame(cosine_sim_matrix, index=tags_genres_pivot.index, columns=tags_genres_pivot.index )\n",
    "\n",
    "# 4) Export\n",
    "cosine_sim_id.to_csv(\"data/movies_cosine_sim.csv\")\n",
    "\n",
    "# cosine_sim_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbea5a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF and TF-IDF Frequency\n",
    "# -----------------------\n",
    "\n",
    "# 1) Create Groups\n",
    "total_tags_per_movie = tags_r.groupby(\"movieId\")[\"tag\"].count()\n",
    "type_of_tag_per_movie = tags_r.groupby([\"movieId\",\"tag\"])[\"tag\"]\n",
    "\n",
    "# TF\n",
    "# To get the tag frequency, divide each tag in the movie with \n",
    "# the total number of tags in the movie. \n",
    "tf = type_of_tag_per_movie.apply(lambda x: x.count() / total_tags_per_movie[x.name[0]])\n",
    "\n",
    "# TF-IDF\n",
    "# !) More TF-IDF is added after the genres are add\n",
    "tf_idf = tags_r.groupby([\"movieId\",\"tag\"])[\"tag\"].count()\n",
    "\n",
    "\n",
    "# 2) Add genres and adjust there weight\n",
    "#    combined_weight = True  : The weight will be divided between the genres in the movie\n",
    "#    combined_weight = False : The genres in the movie will be set to weight \n",
    "def add_genres(weight, combined_weight=True):\n",
    "    genres_per_movie = genres_r.groupby(\"movieId\")[\"genres\"].count()\n",
    "    genres_tf_idf = genres_r.copy()\n",
    "    \n",
    "    # !) .get() is needed because all movies have at aleast one \n",
    "    #    gnerea to there name, but not all movies have tags  \n",
    "    if combined_weight:\n",
    "        genres_tf_idf[\"tf\"]  = genres_r[\"movieId\"].apply(lambda x: weight/genres_per_movie[x])\n",
    "        genres_tf_idf[\"idf\"] = genres_r[\"movieId\"].apply(lambda x: (total_tags_per_movie.get(x,1)*weight)/genres_per_movie[x] )\n",
    "    else:\n",
    "        genres_tf_idf[\"tf\"]  = genres_r[\"movieId\"].apply(lambda x: weight)\n",
    "        genres_tf_idf[\"idf\"] = genres_r[\"movieId\"].apply(lambda x: total_tags_per_movie.get(x,1)*weight)\n",
    "\n",
    "\n",
    "    for row in genres_tf_idf.itertuples():\n",
    "        tf[row.movieId, row.genres] = row.tf\n",
    "        tf_idf[row.movieId, row.genres] = row.idf\n",
    "\n",
    "add_genres(1, False)\n",
    "\n",
    "\n",
    "# 3) Create tf-idf\n",
    "# Note that type_of_tag_per_movie_gbo is used as framework because it has the \n",
    "# groupby structure so one can use .apply and get both the x.count() and the \n",
    "# associated index aka the movieId and tag\n",
    "documents = tf_idf.index.shape[0]\n",
    "idf = tf_idf.unstack().count().apply(lambda x: np.log(documents/x))\n",
    "\n",
    "terms_per_document = tf_idf.groupby(\"movieId\").sum()\n",
    "tf_ = type_of_tag_per_movie.apply(lambda x: tf_idf[x.name[0], x.name[1]] / terms_per_document[x.name[0]])\n",
    "\n",
    "tf_idf = type_of_tag_per_movie.apply(lambda x: tf_[x.name[0], x.name[1]] * idf[x.name[1]])\n",
    "\n",
    "\n",
    "# 4) Remove tags with low weight\n",
    "#    At < 0.0099 it removes 15% of all tags\n",
    "def remove_tags(tags, threshold, verbose=False):\n",
    "    pre = tags.shape[0]\n",
    "    mask = tags < 0.0099\n",
    "    tags = tags.loc[~mask] \n",
    "    if verbose: \n",
    "        print(tags.shape[0]/pre)\n",
    "    return tags\n",
    "\n",
    "tf = remove_tags(tf, 0.0099)\n",
    "tf_idf = remove_tags(tf_idf, 0.0099)\n",
    "\n",
    "\n",
    "# 5) Cosine Similarity\n",
    "#    Use the TF or TF_IDF weight adjusted tags as a base for cosine similarity\n",
    "#\n",
    "# !) If you want to use reset_index then make sure that the index names  \n",
    "#    don't clash with the Series name. Set .pivot index to the Series\n",
    "#    index and .pivot values to the Series name\n",
    "def cosin_sim(tags):\n",
    "    tags.name = \"weights\"\n",
    "    tags = tags.reset_index()\n",
    "    tags_pivot = tags.pivot(index=\"movieId\", columns=\"tag\", values=\"weights\")\n",
    "    tags_pivot.fillna(0, inplace=True)\n",
    "    return cosine_similarity(tags_pivot), tags_pivot\n",
    "\n",
    "tf_cs_matrix, tf_pivot = cosin_sim(tf)\n",
    "tf_idf_cs_matrix, tf_idf_pivot = cosin_sim(tf_idf)\n",
    "\n",
    "\n",
    "tf_cs_matrix = pd.DataFrame(tf_cs_matrix, index=tf_pivot.index, columns=tf_pivot.index )\n",
    "tf_idf_cs_matrix = pd.DataFrame(tf_idf_cs_matrix, index=tf_idf_pivot.index, columns=tf_idf_pivot.index )\n",
    "\n",
    "# 6) Export\n",
    "tf_cs_matrix.to_csv(\"data/tf_cosine_sim.csv\")\n",
    "tf_idf_cs_matrix.to_csv(\"data/tf_idf_cosine_sim.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1e308b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# User Input Interpreter\n",
    "# ----------------------\n",
    "# Creates a Data Frame that is used when the app deals with user inputs\n",
    "\n",
    "# 1) Prep titles_r\n",
    "titles_to_exp = titles_r.copy().set_index(\"movieId\", drop=True)\n",
    "\n",
    "# 2) Regulare expression used to split up the movie titles\n",
    "#    Technically there are more prefixs then 'a' and 'the'\n",
    "#    The last group (.)$ is required to catch movies without a year it \n",
    "pattern = r\"(.*?)(, a |, the )?(\\(.*\\) )?(\\(\\d{4})?(.)$\"\n",
    "\n",
    "# 3) Creat the Dataframe\n",
    "#    Note that there are movies with more then one alternative title,\n",
    "#    A function should be implemented in the streamlit app that converts\n",
    "#    non-english characters like Ã© into e\n",
    "titles_exp = pd.DataFrame(index=titles_to_exp.index, columns=[\"prefix\", \"title\", \"alt\", \"title year\", \"alt year\", \"title duplicate\"])\n",
    "titles_exp[\"title duplicate\"] = \"-\"\n",
    "titles_exp[\"alt duplicate\"] = \"-\"\n",
    "\n",
    "# 4) Split up the titles and add them to a Data Frame\n",
    "for row in titles_to_exp.itertuples():\n",
    "    \n",
    "    # Preforms the regular expression group capture\n",
    "    regex_groups = re.findall(pattern, row[1].lower())\n",
    "\n",
    "    # This handles movies that lack a year \n",
    "    regex_groups[0] = list(regex_groups[0])  \n",
    "    last_character = regex_groups[0].pop()\n",
    "    if last_character != ')':     \n",
    "        regex_groups[0][0] += last_character\n",
    "        regex_groups[0].append('(?)')  \n",
    "    else : \n",
    "        regex_groups[0][-1] += ')'\n",
    "\n",
    "    \n",
    "    # !) the if else statment is needed because there is a bug with one of the movies\n",
    "    #    maybe not needed\n",
    "    titles_exp.loc[row[0], \"title\"]=regex_groups[0][0].strip() if regex_groups[0] else str()\n",
    "    \n",
    "    # This cleans up the string contained in the group and preforms\n",
    "    # a little hack to add an empty string if regex don't capture anything\n",
    "    prefix = re.findall(r\"a|the\" ,regex_groups[0][1])\n",
    "    titles_exp.loc[row[0], \"prefix\"]=prefix[0] if prefix else \"-\"\n",
    "    \n",
    "    # Grabs the alternative title of the movie\n",
    "    alt = re.findall(r\"\\(a.k.a. (.*?)\\)|\\((.*?)\\)\" ,regex_groups[0][2])\n",
    "    if alt == []:\n",
    "        alt = \"-\" \n",
    "        alt_year = \"-\"\n",
    "    elif alt[0][0] == \"\":\n",
    "        alt=alt[0][1]\n",
    "        alt_year = f\"{alt} {regex_groups[0][3]}\"\n",
    "    else: \n",
    "        alt=alt[0][0]\n",
    "        alt_year = f\"{alt} {regex_groups[0][3]}\"\n",
    "\n",
    "    # (!) Safty Probably not needed \n",
    "    year = regex_groups[0][3] if regex_groups[0][3] else str()\n",
    "    titles_exp.loc[row[0], \"alt\"]= alt\n",
    "    titles_exp.loc[row[0], \"title year\"]=f\"{regex_groups[0][0]}{regex_groups[0][3]}\"\n",
    "    titles_exp.loc[row[0], \"alt year\"]=alt_year\n",
    "    \n",
    "titles_exp\n",
    "\n",
    "# 5)\n",
    "# !) Not implemented\n",
    "#    Some films have the same tilte, these columns whould \n",
    "#    have been used to prompted user to add a date if they \n",
    "#    entered a title one of these movies. \n",
    "duplicate = titles_exp[titles_exp[\"title\"].duplicated(keep=False)].index\n",
    "for movieId in duplicate:\n",
    "    titles_exp.loc[movieId, \"title duplicate\"] = titles_exp.loc[movieId, \"title\"]\n",
    "# for movieId in duplicate:\n",
    "#     print( titles_exp.loc[movieId, \"title duplicate\"] )\n",
    "\n",
    "duplicate = titles_exp[titles_exp[\"alt\"].duplicated(keep=False)].index\n",
    "for movieId in duplicate:\n",
    "    titles_exp.loc[movieId, \"alt duplicate\"] = titles_exp.loc[movieId, \"alt\"]\n",
    "# for movieId in duplicate:\n",
    "#     print( titles_exp.loc[movieId, \"alt duplicate\"] )\n",
    "\n",
    "# 6) Export\n",
    "titles_exp.to_csv(\"data/titles.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ba49d6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Popularity \n",
    "# ----------\n",
    "# Calculate a popularity score for each movie that can be used \n",
    "# in combination with the cosine tags\n",
    "# 1) Calculate Popularity \n",
    "master_index = titles_exp.index\n",
    "ratings_temp = ratings_r[ ratings_r[\"movieId\"].isin(master_index) ].copy()\n",
    "ratings_temp.drop(columns=\"userId\", inplace=True)\n",
    "popularity = ratings_temp.groupby(\"movieId\").count()\n",
    "\n",
    "# 2) Scale\n",
    "popularity_reshaped = popularity[\"rating\"].values.reshape(-1,1)\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(popularity_reshaped)\n",
    "popularity_scaled = popularity.copy()\n",
    "popularity_scaled[\"rating\"] = scaler.transform(popularity_reshaped)\n",
    "\n",
    "# 3) Export\n",
    "popularity_scaled.to_csv(\"data/popularity.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
